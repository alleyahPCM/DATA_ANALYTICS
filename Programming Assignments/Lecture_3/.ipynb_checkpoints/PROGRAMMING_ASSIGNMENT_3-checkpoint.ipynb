{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "34c46e71-b301-4b08-8469-aecaa0cd61cc",
   "metadata": {},
   "source": [
    "Instructions:\n",
    "-\n",
    "\n",
    "1. Read the article: https://www.sciencedirect.com/science/article/abs/pii/S0031320322001753\n",
    "2. Replicate the study using the same dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "04abe27f-d9e6-48a2-8216-f680dbcd5ec5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from ucimlrepo import fetch_ucirepo \n",
    "\n",
    "zoo = fetch_ucirepo(id=111) \n",
    "\n",
    "X = zoo.data.features\n",
    "y = zoo.data.targets \n",
    "zoo_df = pd.merge(X, y, left_index=True, right_index=True)\n",
    "\n",
    "zoo_df = zoo_df.dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1de73bf8-6f15-41ad-813e-78b2ac972124",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "def jaccard_coefficient(set1, set2):\n",
    "    intersection = len(set1.intersection(set2))\n",
    "    union = len(set1.union(set2))\n",
    "    return intersection / union if union != 0 else 0\n",
    "\n",
    "def ochiai_coefficient(set1, set2):\n",
    "    intersection = len(set1.intersection(set2))\n",
    "    denominator = np.sqrt(len(set1) * len(set2))\n",
    "    return intersection / denominator if denominator != 0 else 0\n",
    "\n",
    "def overlap_coefficient(set1, set2):\n",
    "    intersection = len(set1.intersection(set2))\n",
    "    min_length = min(len(set1), len(set2))\n",
    "    return intersection / min_length if min_length != 0 else 0\n",
    "\n",
    "def dice_coefficient(set1, set2):\n",
    "    intersection = len(set1.intersection(set2))\n",
    "    dice_denominator = len(set1) + len(set2)\n",
    "    return 2 * intersection / dice_denominator if dice_denominator != 0 else 0\n",
    "\n",
    "def graph_based_representation(data, num_components):\n",
    "    num_samples, num_features = data.shape\n",
    "    similarity_matrix = np.zeros((num_features, num_features))\n",
    "    for i, j in itertools.combinations(range(num_features), 2):\n",
    "        similarity_matrix[i, j] = jaccard_coefficient(set(data[:, i]), set(data[:, j]))\n",
    "        similarity_matrix[j, i] = similarity_matrix[i, j]\n",
    "    G = nx.from_numpy_array(similarity_matrix)\n",
    "    embedding = SpectralEmbedding(n_components=num_components)\n",
    "    representation_matrix = embedding.fit_transform(similarity_matrix)\n",
    "    return representation_matrix\n",
    "\n",
    "def joint_operation(data, representation_matrix):\n",
    "    return np.dot(data, representation_matrix)\n",
    "\n",
    "def mean_operation(data, representation_matrix):\n",
    "    return np.mean(np.dot(data, representation_matrix), axis=1)\n",
    "\n",
    "def perform_clustering(data, k):\n",
    "    kmeans = KMeans(n_clusters=k)\n",
    "    return kmeans.fit_predict(data)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f53afaaa-d0bf-4f14-99e2-c2fbeddff1fa",
   "metadata": {},
   "source": [
    "3. Read articles about Adjusted Rand Index, Normalized Mutual Information, and Folkes-Mallows Index (only use paper published in IEEE, sciencedirect, springerlink, Taylor Francis).\n",
    "4. Aside from the Adjusted Rand Index (ARI), and Normalized Mutual Information (NMI), use the Folkes-Mallows Index (FMI), and compare the result of each performance index."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c7df084f-4f2c-46f2-9362-7071e1642655",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Dataset       ARI       NMI       FMI\n",
      "0  zoo_df  0.543157  0.599616  0.683843\n"
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.manifold import SpectralEmbedding\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.metrics import adjusted_rand_score, normalized_mutual_info_score, fowlkes_mallows_score\n",
    "import networkx as nx\n",
    "import itertools\n",
    "\n",
    "p = 10\n",
    "k = 3  \n",
    "\n",
    "dataset = zoo_df\n",
    "\n",
    "results = []\n",
    "\n",
    "try:\n",
    "    if dataset.isnull().values.any():\n",
    "        raise ValueError(\"Dataset contains missing values. Please handle them before proceeding.\")\n",
    "\n",
    "    X = dataset.drop(columns=['type'])  \n",
    "    y = dataset['type'].values         \n",
    "\n",
    "    if not all(pd.api.types.is_numeric_dtype(dtype) or pd.api.types.is_categorical_dtype(dtype) for dtype in X.dtypes):\n",
    "        raise ValueError(\"All features must be numeric or categorical for OneHotEncoder.\")\n",
    "\n",
    "    try:\n",
    "        enc = OneHotEncoder(sparse_output=False)\n",
    "        X_encoded = enc.fit_transform(X)\n",
    "    except Exception as e:\n",
    "        raise ValueError(f\"Error during OneHotEncoder transformation: {e}\")\n",
    "\n",
    "    representation_matrix = graph_based_representation(X_encoded, p)\n",
    "    \n",
    "    integrated_data = joint_operation(X_encoded, representation_matrix)\n",
    "    \n",
    "    labels = perform_clustering(integrated_data, k)\n",
    "\n",
    "    ARI = adjusted_rand_score(y, labels)\n",
    "    NMI = normalized_mutual_info_score(y, labels)\n",
    "    FMI = fowlkes_mallows_score(y, labels)\n",
    "    \n",
    "    results.append(['zoo_df', ARI, NMI, FMI])\n",
    "\n",
    "except ValueError as ve:\n",
    "    print(f\"ValueError: {ve}\")\n",
    "except Exception as e:\n",
    "    print(f\"An unexpected error occurred: {e}\")\n",
    "\n",
    "results_df = pd.DataFrame(results, columns=[\"Dataset\", \"ARI\", \"NMI\", \"FMI\"])\n",
    "print(results_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "554bddcc-f3c5-4b3d-a2a4-a3409bb921e9",
   "metadata": {},
   "source": [
    "5. Compare and contrast each performance index, what are the advantages and disadvantages of ARI, NMI, and FMI, and when to use each?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b045e23b-0d8e-4461-8fbe-b65f7bb32fab",
   "metadata": {},
   "source": [
    "Based on the output, FMI yielded a higher performance with 0.683843 followed by NMI with 0.599616, then ARI with 0.543157.\r\n",
    "\r\n",
    "Adjusted Rand Index (ARI) is applicable when results are divided into two categories. Its advantages include correcting random clustering and its interpretable scale, ranging from -1 to 1. Its disadvantages include assuming a flat clustering structure, making it unsuitable for hierarchical clustering and bias with varying cluster sizes. Use ARI to measure the accuracy of ground truth clustering.\r\n",
    "\r\n",
    "Normalized Mutual Information (NMI) is used to measure the level of fit between two clustering results. Its advantages include equal treatment of true and predicted clustering and normalization. Its disadvantage is poor performance with clusters of different sizes. Use NMI  for comparing two clustering results without bias. \r\n",
    "\r\n",
    "Folkes-Mallows Index (FMI) is the geometric mean of the pairwise precision rate and recall rate. Its advantage is balance, and it does not have assumptions about clusters. Its disadvantage is that it considers pairwise relationships only. Use FMI for balanced evaluation of clustering performance. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ca2a493-3900-4a60-ba00-7f6e686172f8",
   "metadata": {},
   "source": [
    "6. Using Kmodes and Hierarchical Clustering, use the same dataset and perform categorical data clustering, use FMI, ARI, and NMI for the comparison of performance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8dd3555e-3e2c-4c60-a032-42e08e5a98a6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "         Method       ARI       NMI       FMI\n",
      "0        Kmodes  0.733623  0.738007  0.820112\n",
      "1  Hierarchical  0.716368  0.762020  0.812457\n"
     ]
    }
   ],
   "source": [
    "from kmodes.kmodes import KModes\n",
    "from scipy.cluster.hierarchy import linkage, fcluster\n",
    "\n",
    "def perform_kmodes_clustering(data, k):\n",
    "    kmodes = KModes(n_clusters=k, init='Huang', n_init=5, verbose=0)\n",
    "    labels = kmodes.fit_predict(data)\n",
    "    return labels\n",
    "\n",
    "def perform_hierarchical_clustering(data, k):\n",
    "    Z = linkage(data, method='ward')\n",
    "    labels = fcluster(Z, k, criterion='maxclust')\n",
    "    return labels\n",
    "    \n",
    "k = 3\n",
    "\n",
    "dataset = zoo_df\n",
    "\n",
    "results = []\n",
    "\n",
    "try:\n",
    "    if dataset.isnull().values.any():\n",
    "        raise ValueError(\"Dataset contains missing values. Please handle them before proceeding.\")\n",
    "\n",
    "    X = dataset.drop(columns=['type']) \n",
    "    y = dataset['type'].values         \n",
    "\n",
    "    if not all(pd.api.types.is_numeric_dtype(dtype) or pd.api.types.is_categorical_dtype(dtype) for dtype in X.dtypes):\n",
    "        raise ValueError(\"All features must be numeric or categorical for OneHotEncoder.\")\n",
    "\n",
    "    try:\n",
    "        enc = OneHotEncoder(sparse_output=False)\n",
    "        X_encoded = enc.fit_transform(X)\n",
    "    except Exception as e:\n",
    "        raise ValueError(f\"Error during OneHotEncoder transformation: {e}\")\n",
    "\n",
    "    kmodes_labels = perform_kmodes_clustering(X_encoded, k)\n",
    "    ARI_kmodes = adjusted_rand_score(y, kmodes_labels)\n",
    "    NMI_kmodes = normalized_mutual_info_score(y, kmodes_labels)\n",
    "    FMI_kmodes = fowlkes_mallows_score(y, kmodes_labels)\n",
    "    results.append(['Kmodes', ARI_kmodes, NMI_kmodes, FMI_kmodes])\n",
    "\n",
    "    hierarchical_labels = perform_hierarchical_clustering(X_encoded, k)  # No need for toarray()\n",
    "    ARI_hierarchical = adjusted_rand_score(y, hierarchical_labels)\n",
    "    NMI_hierarchical = normalized_mutual_info_score(y, hierarchical_labels)\n",
    "    FMI_hierarchical = fowlkes_mallows_score(y, hierarchical_labels)\n",
    "    results.append(['Hierarchical', ARI_hierarchical, NMI_hierarchical, FMI_hierarchical])\n",
    "\n",
    "except ValueError as ve:\n",
    "    print(f\"ValueError: {ve}\")\n",
    "except Exception as e:\n",
    "    print(f\"An unexpected error occurred: {e}\")\n",
    "\n",
    "results_df = pd.DataFrame(results, columns=[\"Method\", \"ARI\", \"NMI\", \"FMI\"])\n",
    "print(results_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1eaa8fc3-05fe-4f61-891c-f53f3b79b506",
   "metadata": {},
   "source": [
    "7. Write your report using Latex. Your report should be focused on the \"why's and the what's\" of each performance metrices (i.e. why is FMI always greater than ARI and NMI? What's the problem with ARI and NMI?)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "912afac7-5613-4616-bca3-5aee10af0336",
   "metadata": {},
   "source": [
    "In both Kmodes and Hierachical Clustering, Folkes-Mallows Index (FMI) performed better with 0.820112 Kmodes and 0.812457 Hierarchical than Normalized Mutual Information  (NMI) with 0.738007 Kmodes and 0.762020 Hierarchical, followed by Adjusted Rand Index (ARI) with the lowest performance of 0.733623 Kmodes and 0.716368 Hierachical. \n",
    "\n",
    "FMI is always greater than ARI and NMI as it focuses on the pairwise similarity between clusters, entailing the relative proportion of true positive to false positive. Meanwhile, ARI and NMI yield a lower performance as they both consider the true and false positive/negative pairs in computation. ARI and NMI have different normalization schemes and may have limitations with extremely large datasets or highly imbalanced clusters. \r\n",
    "\r\n",
    "Despite such, note that ARI and NMI are more widely used than FMI due to its normalization for fair comparison across algorithms and datasets. Additionally, they are easier to understand and more robust."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
